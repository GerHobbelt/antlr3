group C;

// G R A M M A R  E L E M E N T S

outputFile(LEXER, PARSER, TREE_PARSER, headerAction, docComment, recognizer,
	name, literals, tokens, rules, cyclicDFAs, predicates ) ::=
<<
<headerAction>

#include \<sys/types.h\>
#include \<sys/stat.h\>
#include \<unistd.h\>
#include \<fcntl.h\>
#include \<stdio.h\>
#include \<string.h\>
#include \<stdlib.h\>
#include \<errno.h\>
#include \<assert.h\>
#include \<sys/mman.h\>

#include "<name>.h"

<docComment>
<recognizer>
>>

headerFile(name, literals, tokens, rules, cyclicDFAs, predicates) ::= <<
#ifndef __<name>_H__
#define __<name>_H__

// Return value definitions
// the whole error handling needs a much closer look
enum {
	ANTLR_OK = 0,
	ANTLR_MISMATCH = 1,
	ANTLR_UNEXPECTED_EOF = 2,
	ANTLR_NO_VIABLE_ALT = 3,
	ANTLR_STREAM_ERROR = 4,
	ANTLR_OUT_OF_MEMORY = 5
};

#define TOKEN_EOF (unsigned int)EOF
<tokens:{#define TOKEN_<attr.name> <attr.type>U}; separator="\n">

/* define a token like this for now
 * - line/column/file tracking?
 *   maybe this can be done by loading an extra template or something?
 *   define a template bit in the .g file ?
 * - token text? (it's available (see the main routine)
 */
typedef struct Token {
	unsigned int tokenType;
} TOKEN;

extern const TOKEN EOFToken;

typedef struct LexerContext {
	char* input;				/* input stream (mmaped) */
	size_t size;				/* size of input */
	size_t offset;				/* where are we reading wise */

	char* tokenBuffer;		/* collect current token text here */
	char* tokenBufferEnd;	/* end sentinel */
	char* tokenBufferPtr;	/* where we're at */
	unsigned tokenType;
	int skipToken;
	unsigned line;
} LEXER_CONTEXT;

<rules:{extern int m<it.name>( LEXER_CONTEXT* ctx<if(it.args)>,<endif> <it.args>);}; separator="\n">

#endif
>>

lexer(name, tokens, literals, rules, cyclicDFAs, predicates) ::= <<
/* Lexer code generated for <name> */

/* FIXME:
 * the hash table stuff probably needs some extra thought to get things
 * fully reentrant. Probably things will be ok if the initialization is
 * done once.
 */

/*{{{ Hash table stuff */
#define INIT_TABLE_SIZE	1024
#define HASH_TABLE_SIZE	 256		/* power of 2, keep it in the >0 range */

// type of lookahead
typedef int LA_TYPE;

typedef struct
{
	char *string;				  	/* the string */
	unsigned int len;				/* the length of the string */
	unsigned int value;			/* the token type */
	int collision;					/* collision pointer */
} TABLE_ENTRY;

static TABLE_ENTRY
	*string_table = NULL;

static unsigned long
	table_size = INIT_TABLE_SIZE;

static int
	hash_count = 0,
	hash_table[HASH_TABLE_SIZE];

/* Para's the string to be hashed and the length of it
 * Returns: a hash key for the string, stores the string internally (strdup)
 * if the string wasn't stored before
 * returns -1 on error
 */
int hash_value( char *string, unsigned int value )
{
	int index;
	int current;
	TABLE_ENTRY *t;

	size_t len = strlen(string);

	index = len == 0 ? 0 :	/* hash */
		((int)string[0] +
		 (int)string[len - 1] * 11 + len * 26) &
		 (HASH_TABLE_SIZE - 1);

	current = hash_table[index];

	while (current != 0)
	{
		t = &string_table[current];

		if((t->len == len) && (t->string != NULL) && (strcmp(t->string, string) == 0))
			return current;

		current = t->collision;
	}

	if ((int) ++hash_count == (int) table_size)	/* overflow increase space */
	{
		TABLE_ENTRY *t = (TABLE_ENTRY *)realloc( string_table, (table_size + INIT_TABLE_SIZE) * sizeof( *t ) );
		if ( t == NULL )
			return -1;
		memset( string_table + table_size, 0, INIT_TABLE_SIZE * sizeof(*t) );
		string_table = t;
		table_size += INIT_TABLE_SIZE;
	}

	t = string_table + hash_count;
	t->string = strdup( string );
	t->len = len;
	t->value = value;
	t->collision = hash_table[index];

	hash_table[index] = hash_count;

	return hash_count;
}

int hash_lookup( const char* string, size_t length )
{
	int index;
	int current;
	TABLE_ENTRY *t;

	index = length == 0 ? 0 :	/* hash */
		((int)string[0] +
		 (int)string[length - 1] * 11 + length * 26) &
		 (HASH_TABLE_SIZE - 1);

	current = hash_table[index];

	while (current != 0)
	{
		t = &string_table[current];

		if((t->len == length) && (t->string != NULL) && (strcmp(t->string, string) == 0))
		{
			return t->value;
		}

		current = t->collision;
	}
	return 0;
}

const char *unhash_string( int ident )
{
	if(ident == -1)
		ident = 0;
	return string_table[ident].string;
}

void free_hash_string( void )
{
	int i;

	if (string_table != NULL)
		for( i = 0; i \<= hash_count; i++)
		{
			if( string_table[i].string != NULL )
				free( string_table[i].string );
		}

	if( string_table != NULL )
		free( string_table );
}

/* returns 0 if OK !0 else
 */
int init_hash_string( void )
{
	unsigned int i;

	if( string_table != NULL )
	{
		free_hash_string();
		free( string_table );
	}

	for (i = 0; i \< HASH_TABLE_SIZE; i++)
		hash_table[i] = 0;

	hash_count = 0;

	if((string_table = (TABLE_ENTRY *) calloc( INIT_TABLE_SIZE, sizeof( TABLE_ENTRY ) )) == NULL)
		return -1;

	/* hash_string("", strlen("")); */
	return 0;
}
/*}}}*/

const TOKEN EOFToken = { EOF };

#define INIT_TOKEN_BUFSIZE 1024

/* define stuff for now with real support code this might need some tweakage
 */
#define skip() ctx->skipToken = 1
#define newline() ctx->line++
#define setType(x) ctx->tokenType = x
#define literalCheck() { int tt = hash_lookup(ctx->tokenBuffer, ctx->tokenBufferPtr - ctx->tokenBuffer); if( tt > 0 ) setType(tt); }

void consume( LEXER_CONTEXT* ctx )
{
	ctx->offset++;
}

int LA( LEXER_CONTEXT* ctx, unsigned int i )
{
	size_t offset = ctx->offset+i-1;
	if( offset >= ctx->size )
		return EOF;
	return ctx->input[offset];
}

/* append ch to the tokenBuffer in the context
 * return 0 (OK) if success
 * also takes care of reallocating the buffer it's not big enough
 */
int append( LEXER_CONTEXT* ctx, int ch )
{
	assert(ch != EOF);

	// get a buffer if needed
	if( ctx->tokenBuffer == 0 )
	{
		if( (ctx->tokenBuffer = (char*)malloc(INIT_TOKEN_BUFSIZE)) == NULL )
			return ANTLR_OUT_OF_MEMORY;
		ctx->tokenBufferEnd = ctx->tokenBuffer + INIT_TOKEN_BUFSIZE;
		ctx->tokenBufferPtr = ctx->tokenBuffer;
	}

	// reallocate if needed
	if( ctx->tokenBufferEnd == ctx->tokenBufferPtr )
	{
		size_t offset = ctx->tokenBufferPtr - ctx->tokenBuffer;
		size_t size = ctx->tokenBufferEnd - ctx->tokenBuffer;
		size_t new_size = size * 2;
		char* oldbuf = ctx->tokenBuffer;
		if( (ctx->tokenBuffer = (char*)malloc(new_size)) == NULL )
			return ANTLR_OUT_OF_MEMORY;
		memcpy(ctx->tokenBuffer,oldbuf,size);
		free(oldbuf);
		ctx->tokenBufferEnd = ctx->tokenBuffer + new_size;
		ctx->tokenBufferPtr = ctx->tokenBuffer + offset;
	}
	// add character
	*ctx->tokenBufferPtr++ = ch;
	consume(ctx);
	return ANTLR_OK;
}

int matchChar( LEXER_CONTEXT* ctx, unsigned int c )
{
	int ch = LA(ctx,1);
	if( ch == EOF )
		return ANTLR_UNEXPECTED_EOF;
	if ( (unsigned int)ch != c )
	{
		fprintf(stderr,"mismatched char: %c expected %c\r\n", ch, c );
		return ANTLR_MISMATCH;
	}
	return append( ctx, ch );
}

int matchString( LEXER_CONTEXT* ctx, const char* s )
{
	int ret = ANTLR_OK;
	const char* p = s;
	while( *p != '\0' && ret == ANTLR_OK )
	{
		int ch = LA(ctx,1);
		if( ch == EOF )
			return ANTLR_UNEXPECTED_EOF;
		if( *p != ch )
			return ANTLR_MISMATCH;
		ret = append( ctx, ch );
		p++;
	}
	return ret;
}

int matchRange( LEXER_CONTEXT* ctx, unsigned int low, unsigned int high )
{
	int ch = LA(ctx,1);

	assert(low \< high);

	if( ch == EOF )
		return ANTLR_UNEXPECTED_EOF;
	if( (unsigned int)ch \< low || (unsigned int)ch \> high )
		return ANTLR_MISMATCH;
	return append( ctx, ch );
}

int matchAny( LEXER_CONTEXT* ctx )
{
	int ch = LA(ctx,1);
	if( ch == EOF )
		return ANTLR_UNEXPECTED_EOF;
	return append( ctx, ch );
}

void <name>_init( void ) {
	<literals:{hash_value(<attr.name>, <attr.type>);}; separator="\n">
}

int <name>NextToken( LEXER_CONTEXT* ctx, TOKEN* token ) {
	int ret = ANTLR_OK;
	for(;;)
	{
		ctx->skipToken = 0;

		if( ctx->offset >= ctx->size )
		{
			token->tokenType = TOKEN_EOF;
			return ANTLR_OK;
		}
		ctx->tokenBufferPtr = ctx->tokenBuffer;

		if( (ret = mTokens(ctx)) != ANTLR_OK )
			return ret;

		if ( !ctx->skipToken )
			break;
	}
#if 0
	/* get the text */
	token->text = strndup( context.tokenBuffer, ctx->tokenBufferPtr - ctx->tokenBuffer );
#endif
	token->tokenType = ctx->tokenType;
	return ANTLR_OK;
}

/* test stub */
int main( int argc, char** argv )
{
	LEXER_CONTEXT context;
	int fd;
	struct stat st;

	init_hash_string();
	<name>_init();

	if( argc != 2 )
	{
		fprintf( stderr, "Usage: %s \<file>\n\r",argv[0] );
		return 1;
	}

	if( (fd = open(argv[1], O_RDONLY)) == -1 )
	{
		fprintf( stderr, "Error opening: %s - %s\n\r",argv[1], strerror(errno) );
		return 1;
	}
	if( fstat(fd,&st) != 0 )
	{
		fprintf( stderr, "Error stat-ing: %s - %s\n\r",argv[1], strerror(errno) );
		close(fd);
		return 1;
	}

	context.size = st.st_size;
	context.offset = 0;

	if( (context.input = mmap(0,st.st_size,PROT_READ,MAP_PRIVATE,fd,0) ) == MAP_FAILED )
	{
		fprintf( stderr, "Error mmap-ing: %s - %s\n\r",argv[1], strerror(errno) );
		close(fd);
		return 1;
	}

	context.tokenBuffer = context.tokenBufferEnd = context.tokenBufferPtr = 0;
	context.skipToken = 0;
	context.line = 0;

	for(;;)
	{
		TOKEN tok;
		int ret;

		ret = <name>NextToken( &context, &tok );
		if( tok.tokenType == TOKEN_EOF )
			break;
		if( ret != ANTLR_OK )
			break;
		context.tokenBufferPtr[0] = '\0';
		printf( "Found tokentype %d - %s\r\n", tok.tokenType, context.tokenBuffer );
	}
	munmap(context.input,st.st_size);
	close(fd);
	return 0;
}

/* DFA's */
<cyclicDFAs>

/* rules */
<rules; separator="\n">

/* End of lexer definition for <name> */
>>

parser(name, tokens, rules, cyclicDFAs, predicates) ::= <<

typedef struct Token {
	unsigned int tokenType;
} TOKEN;

typedef struct LexerContext {
	char* input;				/* input stream (mmaped) */
	size_t size;				/* size of input */
	size_t offset;				/* where are we reading wise */

	char* tokenBuffer;		/* collect current token text here */
	char* tokenBufferEnd;	/* end sentinel */
	char* tokenBufferPtr;	/* where we're at */
	unsigned tokenType;
	int skipToken;
	unsigned line;
} LEXER_CONTEXT;

// Return value definitions
// the whole error handling needs a much closer look
enum {
	ANTLR_OK = 0,
	ANTLR_MISMATCH = 1,
	ANTLR_UNEXPECTED_EOF = 2,
	ANTLR_NO_VIABLE_ALT = 3,
	ANTLR_STREAM_ERROR = 4,
	ANTLR_OUT_OF_MEMORY = 5
};

#define INIT_TOKEN_BUFFER_SIZE 10

typedef struct TokenBuffer {
	LEXER_CONTEXT* lctx;
	TOKEN (*next_token)( LEXER_CONTEXT* ctx );		/* our lexer */
	TOKEN* buffer;			/* the buffer */
	size_t size;			/* size of the buffer */
	size_t offset;			/* read offset */
	size_t count;			/* number of elements in buffer */
} TOKEN_BUFFER;

typedef struct ParserContext {
	TOKEN_BUFFER *input;
} PARSER_CONTEXT;

void fillTokenBuffer( TOKEN_BUFFER* tb, size_t n )
{
	while( tb->count \< n )
	{
		if( tb->count == tb->size )		// get new buffer if overflow
		{
			TOKEN* nb = (TOKEN*)calloc(tb->size*2,sizeof(TOKEN));
			memcpy(nb, tb->buffer, tb->size*sizeof(TOKEN));
			free(tb->buffer);
			tb->buffer = nb;
			tb->size = tb->size*2;
		}
		tb->buffer[tb->offset+tb->count % tb->size] = tb->next_token(tb->lctx);
		tb->count++;
	}
}

void consume( PARSER_CONTEXT* ctx )
{
	ctx->input->offset = (ctx->input->offset+1)%ctx->input->size;
}

unsigned int LA( PARSER_CONTEXT* ctx, unsigned int i )
{
	TOKEN_BUFFER* tb = ctx->input;
	fillTokenBuffer( tb, i );
	return tb->buffer[tb->offset+i].tokenType;
}

/* Token definitions */
#define TOKEN_EOF (unsigned int)EOF
<tokens:{#define TOKEN_<attr.name> <attr.type>U}; separator="\n">

int <name>Parser( PARSER_CONTEXT* ctx, LEXER_CONTEXT* lctx )
{
	TOKEN_BUFFER* tb = ctx->input = (TOKEN_BUFFER*)malloc(sizeof(TOKEN_BUFFER));
	tb->lctx = lctx;
	tb->buffer = (TOKEN*)calloc(INIT_TOKEN_BUFFER_SIZE,sizeof(TOKEN));
	tb->size = INIT_TOKEN_BUFFER_SIZE;
	tb->offset = 0;
	tb->count = 0;
}
<cyclicDFAs>

<rules; separator="\n">

>>

rule(name,args,block,enterAction,exitAction) ::= <<
int <name>( PARSER_CONTEXT* ctx<if(args)>,<endif> <args>)
{
	int ret = ANTLR_OK;
<if(enterAction)>
	<enterAction>
<endif>
	<block>
<if(enterAction)>
	<exitAction>
<endif>
	return ret;
}
>>

lexerRule(name,isTokenRuleName,args,block,enterAction,exitAction) ::= <<
int m<name>( LEXER_CONTEXT* ctx<if(args)>,<endif> <args>) /* <isTokenRuleName> */
{
	int ret = ANTLR_OK;
<if(enterAction)>
	<enterAction>
<endif>
<if(isTokenRuleName)>
	<block>
<else>
	<block>
	ctx->tokenType = TOKEN_<name>;
<endif>
<if(enterAction)>
	<exitAction>
<endif>
	return ret;
}
>>

blockSingleAlt(alts,decls,decision,decisionNumber,preamble) ::= <<if( ret == ANTLR_OK )
{
    <preamble>
    <decls>
    <alts>
}
>>

block(alts,decls,decision,decisionNumber,preamble,maxK) ::= <<if( ret == ANTLR_OK )
{
	<preamble>
	unsigned int alt<decisionNumber>;

	alt<decisionNumber> = 0;
	<decls>
	<decision>
	if( ret == ANTLR_OK )
	{
		switch (alt<decisionNumber>) {
		<alts:altSwitchCase()>
		}
	}
}
>>

positiveClosureBlock(alts,decls,decision,decisionNumber,maxK) ::= <<if( ret == ANTLR_OK )
{
	unsigned int cnt<decisionNumber> = 0;
	unsigned int alt<decisionNumber> = 0;
	<decls>
	for(;;) {
		alt<decisionNumber> = 0;
		<decision>
		if( ret != ANTLR_OK )
			goto endLoop<decisionNumber>;

		switch (alt<decisionNumber>) {
		<alts:altSwitchCase()>
		default :
			if ( cnt<decisionNumber> >= 1 )
				goto endLoop<decisionNumber>;
			<if(LEXER)>else
				fprintf(stderr,"line %d: no viable alt in decision <decisionNumber> LA(1)==%c\r\n",ctx->line, LA(ctx,1) );
			<else>else
				fprintf(stderr,"no viable alt in decision <decisionNumber> LT(1)==%d\r\n", LA(ctx,1) );
			<endif>
		}
	cnt<decisionNumber>++;
	}
endLoop<decisionNumber>: ;
}
>>

positiveClosureBlockSingleAlt ::= positiveClosureBlock

closureBlock(alts,decls,decision,decisionNumber,maxK) ::= <<if( ret == ANTLR_OK )
{
	<decls>
	for(;;)
	{
		unsigned int alt<decisionNumber>;
		alt<decisionNumber> = 0;
		<decision>
		if( ret != ANTLR_OK )
			goto loop<decisionNumber>;

		switch (alt<decisionNumber>) {
		<alts:altSwitchCase()>
		default :
			goto loop<decisionNumber>;
		}
	}
loop<decisionNumber>: ;
}
>>

closureBlockSingleAlt ::= closureBlock

optionalBlock ::= block

optionalBlockSingleAlt ::= block

altSwitchCase() ::= <<
case <i> :
	<attr>
	break;
>>

alt(elements) ::= "<elements; separator=\"\n\">"

tokenRef(token) ::= "match(TOKEN_<token>);"

charRef(char) ::= "ret = matchChar( ctx, <char> );"

charRangeRef(a,b) ::= "ret = matchRange( ctx, <a>,<b> );"

matchSet(s) ::= << /* matchSet */
if ( ! ( <s> ) )
{
	if( LA(ctx,1) >= ' ' && LA(ctx,1) \< 255 )
		fprintf( stderr, "line %d: set mismatch '%c'\r\n", ctx->line, LA(ctx,1) );
	else
		fprintf( stderr, "line %d: set mismatch %d\r\n", ctx->line, LA(ctx,1) );
	ret = ANTLR_MISMATCH;
}
else
	ret = append( ctx, LA(ctx,1) );
>>

matchNotSet(s) ::= <<
/* match not */
if ( <s> )
{
	if( LA(ctx,1) >= ' ' && LA(ctx,1) \< 255 )
		fprintf( stderr, "line %d: ~set mismatch '%c'\r\n", ctx->line, LA(ctx,1) );
	else
		fprintf( stderr, "line %d: ~set mismatch %d\r\n", ctx->line, LA(ctx,1) );
	ret = ANTLR_MISMATCH;
}
else
	ret = append( ctx, LA(ctx,1) );
>>

lexerStringRef(string) ::= "ret = matchString( ctx, <string> );"

wildcard() ::= "ret = matchAny();"

wildcardChar() ::= "ret = matchAny( ctx );"

ruleRef(rule,args) ::= "<rule>( ctx<if(args)>, <endif><args> ); /* ruleRef */"

lexerRuleRef(rule,args) ::= "ret = m<rule>( ctx<if(args)>,<endif> <args> );"

// F i x e d  D F A  s t u f f

dfaDecision(decisionNumber,description) ::=
	"alt<decisionNumber> = predictDFA<decisionNumber>(ctx);"

allCyclicDFAs(cyclicDFAs) ::= <<
.method \<init> ()V 1
        aload 0
        invokespecial java/lang/Object.\<init>()V
        return
<cyclicDFAs>
>>

cyclicDFA(decision,states,description) ::= <<

static int DFA<decision>( <if(LEXER)>LEXER_CONTEXT<endif><if(PARSER)>PARSER_CONTEXT<endif>* ctx )
{
	goto s0;
	<states>
}

static int predictDFA<decision>( <if(LEXER)>LEXER_CONTEXT<endif><if(PARSER)>PARSER_CONTEXT<endif>* ctx )
{
	size_t offset_save = ctx->offset;	/* mark */
	int ret = DFA<decision>(ctx);
	ctx->offset = offset_save;				/* rewind */
	return ret;
}

>>

cyclicDFAState(stateNumber,edges,needErrorClause) ::= <<s<stateNumber>:
	<edges>
	<if(needErrorClause)><if(LEXER)>fprintf( stderr, "line %d: no viable alt c=%c", ctx->line, LA(ctx,1) );
	<else>fprintf(stderr,"line %d: <description> - no viable alt token=",ctx->line, LT(ctx,1) );
	<endif>
	return ANTLR_NO_VIABLE_ALT;<endif>
>>

cyclicDFAAcceptState(stateNumber,predictAlt) ::= <<
s<stateNumber>:
	return <predictAlt>;
>>

cyclicDFAEdge(labelExpr, targetStateNumber, edgeNumber) ::= <<
if ( <labelExpr> )	/* unused edgenumber? : <edgeNumber> */
{
	consume(ctx);
	goto s<targetStateNumber>;
}
>>

eotDFAEdge(targetStateNumber,edgeNumber) ::= <<
goto s<targetStateNumber>;
>>

dfaState(edges,defaultClause,eotPredictsAlt,description) ::= <<
<edges; separator="else ">else
{
<if(eotPredictsAlt)>
    alt<decisionNumber> = <eotPredictsAlt>; /* dfaState */
<else>
<if(LEXER)>
	fprintf(stderr,"line %d: no viable alt for c='%c'\r\n",ctx->line,LA(ctx,1));
	ret = ANTLR_NO_VIABLE_ALT;
<else>
	fprintf(stderr,"line %d: no viable alt token=%d\r\n",LA(ctx,1));
<endif>
	consume(ctx);
<endif>
}
>>

dfaAcceptState(alt) ::= "alt<decisionNumber> = <alt>;"

dfaEdge(labelExpr, targetState) ::= <<if ( <labelExpr> )
{
	<targetState>
}
>>

// D F A  E X P R E S S I O N S

andPredicates(left,right) ::= "( <left> && <right> )"

orPredicates(left,right) ::= "( <left> || <right> )"

notPredicate(pred) ::= "!( <pred> )"

lookaheadTest(atom,k,atomAsInt) ::= "LA(ctx,<k>) == <atom> /* k=<k> val=<atomAsInt> */"

lookaheadRangeTest(lower,upper,k,rangeNumber,lowerAsInt,upperAsInt) ::=
	"( LA(ctx,<k>) >= <lower> && LA(ctx,<k>) \<= <upper> ) /* <lowerAsInt> <upperAsInt>*/"

setTest(ranges) ::= "<ranges; separator=\" || \">"

// A C T I O N S

emit(type) ::= "emit(<type>);"

setType(type) ::= "ctx->tokenType = TOKEN_<type>;"

// M I S C

codeFileExtension() ::= ".c"
