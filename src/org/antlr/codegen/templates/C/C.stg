/*
 [The "BSD licence"]
 Copyright (c) 2005 Terence Parr
 All rights reserved.

 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions
 are met:
 1. Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
 2. Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.
 3. The name of the author may not be used to endorse or promote products
    derived from this software without specific prior written permission.

 THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

/*
 * This code generating snarf blargle template thingy was cobbled together
 * by Jim "Any relation to Eric?" Idle. If it does cause the destruction of the
 * UniVerse, it will be pretty cool so long as I am in a different one at the
 * time. 
 */
group C : ANTLRCore ;

cTypeInitMap ::= [
	"int"       : "0",              // Integers     start out being 0
	"long"      : "0",              // Longs        start out being 0
	"float"     : "0.0",            // Floats       start out being 0
	"double"    : "0.0",            // Doubles      start out being 0
	"boolean"   : "ANTLR3_FALSE",   // Booleans     start out being Antlr C for false
	"byte"      : "0",              // Bytes        start out being 0
	"short"     : "0",              // Shorts       start out being 0
	"char"      : "0",              // Chars        start out being 0
	default     : "NULL"            // Anything other than an atomic type (above) is a NULL (probably NULL pointer).
]

leadIn(type) ::=
<<
/** \file
 *  This <type> file was generated by $ANTLR version <ANTLRVersion>
 *
 *     -  From the grammar source file : <fileName>
 *     -                            On : <generatedTimestamp>
<if(LEXER)>
 *     -                 for the lexer : <name>Lexer
<endif>
<if(PARSER)>
 *     -                for the parser : <name>Parser
<endif>
<if(TREE_PARSER)>
 *     -           for the tree parser : <name>TreeParser
<endif>
 *
 * Editing it, at least manually, is not wise. 
 *
 * C language generator and runtime by Jim "Any relation to Eric?" Idle - "jimi" at idledotws
 *
 * View this file with tabs set to 8 (:set ts=8 in gvim) and indent at 4 (:set sw=4 in gvim)
 *
>>

/** The overall file structure of a recognizer; stores methods for rules
 *  and cyclic DFAs plus support code.
 */
outputFile( LEXER,
            PARSER,
            TREE_PARSER,
            actionScope, 
	    backtracking, 
            synpreds, 
            memoize, 
            numRules,
            actions,
            docComment, 
            recognizer,
            name, 
            tokens, 
            tokenNames, 
            rules,
            cyclicDFAs,
            bitsets,
            buildTemplate,
            profile,
            fileName,
            ANTLRVersion,
            generatedTimestamp,
            trace
            ) ::=
<<
<leadIn("C source")>
*/
<if(actions.(actionScope).header)>

/* =============================================================================
 * This is what the grammar programmer asked us to put at the top of every file.
 */
<actions.(actionScope).header>
/* End of Header action.
 * =============================================================================
 */
<endif>

/* -----------------------------------------
 * Include the ANTLR3 generated header file.
 */
#include    \<<name>.h\>

/* ----------------------------------------- */

<docComment>

/* =============================================================================
 * Functions to create and destroy scopes. First come the rule scopes, followed
 * by the global declared scopes.
 */

<rules: {r |<if(r.ruleDescriptor.ruleScope)>

<ruleAttributeScopeFuncDecl(scope=r.ruleDescriptor.ruleScope)>
<ruleAttributeScopeFuncs(scope=r.ruleDescriptor.ruleScope)>
<endif>}>

<recognizer.scopes:{<if(it.isDynamicGlobalScope)>
<ruleAttributeScopeDef(scope=it)>
<globalAttributeScopeFuncDecl(scope=it)>
<globalAttributeScopeFuncs(scope=it)>
<endif>}>

/* ============================================================================= */

/* =============================================================================
 * Start of recognizer
 */

<recognizer>

/* End of code
 * =============================================================================
 */

>>

headerFile( LEXER,
            PARSER,
            TREE_PARSER,
            actionScope,
	    backtracking, 
            synpreds, 
            memoize, 
            numRules, 
            actions,
            docComment, 
            recognizer,
            name, 
            tokens, 
            tokenNames, 
            rules,
            cyclicDFAs,
            bitsets,
            buildTemplate,
            profile,
            fileName,
            ANTLRVersion,
            generatedTimestamp,
            scopes,
            trace
        ) ::=
<<
<leadIn("C header")>
<if(PARSER)>
 * The parser <mainName()>
<endif>
<if(LEXER)>
 * The lexer <mainName()>
<endif>
<if(TREE_PARSER)>
 * The tree parser <mainName()>
<endif>
has the callable functions (rules) shown below,
 * which will invoke the code for the associated rule in the source grammar
 * assuming that the input stream is pointing to a token/text stream that could begin
 * this rule.
 * 
 * For instance if you call the first (topmost) rule in a parser grammar, you will
 * get the results of a full parse, but calling a rule half way through the grammar will
 * allow you to pass part of a full token stream to the parser, such as for syntax checking
 * in editors and so on.
 *
 * The parser entry points are called indirectly (by function pointer to function) via
 * a parser context typedef p<name>_CONTEXT, which is returned from a call to <mainName()>_new().
 *
 * The entry points for <name>Parser are then as follows:
 *
 * <rules: {r |  - <headerReturnType(ruleDescriptor=r.ruleDescriptor)>      p<name>_CONTEXT-><r.ruleDescriptor.name>()}; separator="\n * ">
 *
 * The return type for any particular rule is of course determined by the source
 * grammar file.
 */

<actions.(actionScope).headerfile>
<@includes>

<if(TREE_PARSER)>
/* If this is a tree parser then we need the generic include file for that.
 * Later on I will think through the inheritence thingy and come up with
 * a cunning plan that cannot fail! So, if you see this comment, you are using an
 * early access prototype, as unless I forget, this comment will be taken out once
 * I have swizzled tree node types and so on.
 */

/* =============================================================================
 * Runtime definitions for the generic tree parser
 */
#include \<antlr3/c/treeparser.h>

/* End of runtime definitions for the generic tree parser.
 * =============================================================================
 */
<endif>

/* =============================================================================
 * Standard antlr3 C runtime definitions
 */
#include    \<antlr3/c/antlr3.h>

/* End of standard antlr 3 runtime definitions
 * =============================================================================
 */
<if(backtracking)>
/* We are doing some backtracking ... */
<endif>
<@end>
<if(LEXER)>

/** \brief Token definitions for the lexer.
 *
 * These are the tokens that this lexer is able to spit out.
 * =============================================================================
 * \{
 */

<tokens:{#define <it.name>      <it.type>}; separator="\n">

/* End of token set that this lexer provides
 */
/**  \}  */

/**
 * Cyclic DFA's to drive this lexer
 * =============================================================================
 * \{
 */
<cyclicDFAs>

/* End of Cyclic DFAs
 * =============================================================================
 */
/** \} */

/* Function protoypes for the lexer functions
 */
ANTLR3_API pANTLR3_LEXER <name>Lexer_new         (pANTLR3_CHARSTREAM     input);
ANTLR3_API ANTLR3_RESULT <name>Lexer_nextToken   (pANTLR3_LEXER          lexerContext);
<endif>
<if(PARSER)>
<endif>

<rules:{r |<headerReturnScope(ruleDescriptor=r.ruleDescriptor)>}; separator="\n">

<scopes:{<if(it.isDynamicGlobalScope)><globalAttributeScopeDecl(scope=it)><endif>}>
<rules:{r |<ruleAttributeScopeDecl(scope=r.ruleDescriptor.ruleScope)>}>

/** Context tracking structure for <mainName()>
 */
typedef struct <name>_Ctx_STRUCT
{
    /** Built in ANTLR3 context tracker contains all the generic elements
     *  required for context tracking.
     */
<if(PARSER)>
    ANTLR3_PARSER_CONTEXT   
<endif>
<if(LEXER)>
    ANTLR3_LEXER_CONTEXT    
<endif>
<if(TREE_PARSER)>
    ANTLR3_TREE_PARSER_CONTEXT
<endif>
      antlr3Ctx;
<scopes:{<if(it.isDynamicGlobalScope)>

    <globalAttributeScopeDef(scope=it)>
<endif>}; separator="\n\n">
<rules: {r |<if(r.ruleDescriptor.ruleScope)>

    <ruleAttributeScopeDef(scope=r.ruleDescriptor.ruleScope)>
<endif>}; separator="\n">

    <rules:{r | <headerReturnType(ruleDescriptor=r.ruleDescriptor)> (*<r.ruleDescriptor.name>)(p<name>_CONTEXT ctx<if(r.ruleDescriptor.parameterScope)>, <endif><r.ruleDescriptor.parameterScope:parameterScope(scope=it)>)}; separator=";\n";>
    
    pANTLR3_WCHAR    * getTokenNames();     /** Function to return the table of token names */

}
    * p<name>_CONTEXT;

/** Symbolic definitions of all the tokens that the <grammarType()> will work with.
 *
 * \{
 */    
<tokens:{#define <it.name>      <it.type>}; separator="\n">
   
/* End of token definitions for <name>
 * =============================================================================
 */
/** \} */


>>

grammarType() ::= <<
<if(PARSER)>
parser
<endif>
<if(LEXER)>
lexer
<endif>
<if(TREE_PARSER)>
tree parser
<endif>
>>

mainName() ::= <<
<if(PARSER)>
<name>
<endif>
<if(LEXER)>
<name>
<endif>
<if(TREE_PARSER)>
<name>
<endif>
>>

headerReturnScope(ruleDescriptor) ::= "<returnScope(scope=ruleDescriptor.returnScope)>"

headerReturnType(ruleDescriptor) ::= "<returnType()>"

lexer(name, tokens, rules, numRules, cyclicDFAs) ::= <<
public class <name> extends Lexer {
    <tokens:{public static final int <it.name>=<it.type>;}; separator="\n">
    <actions.lexer.members>
    public <name>(CharStream input) {
        super(input);
    }
    public Token nextToken() {
        token=null;
retry:
        while (true) {
            if ( input.LA(1)==CharStream.EOF ) {
                return Token.EOF_TOKEN;
            }	
            try {
                mTokens();
                break retry;
            }
            catch (RecognitionException re) {
                reportError(re);
                recover(re);
            }
        }
        return token;
    }

    <rules; separator="\n\n">

    <synpreds:{p | <lexerSynpred(name=p)>}>

    <cyclicDFAs:{dfa | protected DFA<dfa.decisionNumber> dfa<dfa.decisionNumber> = new DFA<dfa.decisionNumber>();}>
    <cyclicDFAs>
}
>>

/** How to generate a parser */
genericParser(  name, 
                scopes, 
                tokens, 
                tokenNames, 
                rules, 
                numRules,
                cyclicDFAs,
                bitsets,
                inputStreamType,
                superClass,
                ASTLabelType="Object",
                labelType
              ) ::= <<

/** \brief Table of all token names in symbolic order, mainly used for
 *         error reporting.
 */
static pANTLR3_WCHAR   <name>TokenNames[]
     = {
        "\<invalid>",       /* String to print to indicate an invalid token */
        "\<EOR>",
        "\<DOWN>", 
        "\<UP>", 
        <tokenNames; separator=",\n">
       };

    <@members>

<if(memoize)>

/** Boolean switches, one per rull so that memoization can test whether we
 *  have already failed this rule or not.
 */
static ANTLR3_BOOL ruleMemo[<numRules>+1];<\n> <! index from 1..n !>
<endif>

    <@end>

/** Return token names used by this <grammarType()>
 *
 * The returned pointer is used as an index into the token names table (using the token 
 * number as the index).
 * 
 * \return Pointer to first char * in the table.
 */
static pANTLR3_WCHAR    * getTokenNames() 
{
        return &<name>TokenNames; 
}

<actions.parser.members>

<rules; separator="\n\n">

<! define a singleton instance for each cyclic DFA then define DFAs !>
<cyclicDFAs:{dfa | protected DFA<dfa.decisionNumber> dfa<dfa.decisionNumber> = new DFA<dfa.decisionNumber>();}>
<cyclicDFAs>

<synpreds:{p | <synpred(name=p)>}>

<bitsets:bitset(name={FOLLOW_<it.name>_in_<it.inName><it.tokenIndex>},
                    words64=it.bits)>

>>

parser(name, scopes, tokens, tokenNames, rules, numRules, cyclicDFAs, bitsets, ASTLabelType, superClass="Parser", labelType="Token") ::= <<
<genericParser(inputStreamType="TokenStream", ...)>
>>

/** How to generate a tree parser; same as parser except the input
 *  stream is a different type.
 */
treeParser(name, scopes, tokens, tokenNames, globalAction, rules, numRules, cyclicDFAs, bitsets, labelType={<ASTLabelType>}, ASTLabelType="Object", superClass="TreeParser") ::= <<
<genericParser(inputStreamType="TreeNodeStream", ...)>
>>

synpred(name) ::= <<
class <name>Ptr implements GrammarFragmentPtr {
    public void invoke() throws RecognitionException {<name>_fragment();}
}
<name>Ptr <name> = new <name>Ptr();<\n>
>>

lexerSynpred(name) ::= <<
class <name>Ptr implements GrammarFragmentPtr {
    public void invoke() throws RecognitionException {m<name>_fragment();}
}
<name>Ptr <name> = new <name>Ptr();<\n>
>>

ruleMemoization(name) ::= <<
<if(memoize)>
if ( backtracking>0 && alreadyParsedRule(input, <ruleDescriptor.index>) ) { return <ruleReturnValue()>; }
<endif>
>>

/** How to test for failure and return from rule */
checkRuleBacktrackFailure() ::= <<
<if(backtracking)>if (failed) return <ruleReturnValue()>;<endif>
>>

/** This rule has failed, exit indicating failure during backtrack */
ruleBacktrackFailure() ::= <<
<if(backtracking)>if (backtracking>0) {failed=true; return <ruleReturnValue()>;}<endif>
>>

/** How to generate code for a rule.  This includes any return type
 *  data aggregates required for multiple return values.
 */
rule(ruleName,ruleDescriptor,block,emptyRule,description,exceptions) ::= <<


/** $ANTLR start <ruleName>
 * <fileName>:<description>
 */
static <returnType()> <ruleName>(p<name>_CONTEXT ctx<if(ruleDescriptor.parameterScope)>, <endif><ruleDescriptor.parameterScope:parameterScope(scope=it)>)
{   
    <if(trace)>printf("enter <ruleName> %s failed=%d, backtracking=%d\n", input.LT(1), backtracking);<endif>
    <ruleDeclarations()>
    <ruleLabelDefs()>
    <ruleDescriptor.actions.init>
    <@preamble()>
    <ruleMemoization(name=ruleName)>
    try {
        <block>
    }
<if(exceptions)>
    <exceptions:{e|<catch(decl=e.decl,action=e.action)><\n>}>
<else>
<if(!emptyRule)>
    catch (RecognitionException re) {
        reportError(re);
        recover(input,re);
    }<\n>
<endif>
<endif>
    finally {
        <if(trace)>System.out.println("exit <ruleName> "+input.LT(1)+" failed="+failed+" backtracking="+backtracking);<endif>
        <ruleCleanUp()>
    }
    <@postamble()>
    return <ruleReturnValue()>;
}
// $ANTLR end <ruleName>
>>

catch(decl,action) ::= <<
catch (<e.decl>) {
    <e.action>
}
>>

ruleDeclarations() ::= <<
<ruleDescriptor.useScopes:{<it>_stack.push(new <it>_scope());}; separator="\n">
<ruleDescriptor.ruleScope:{<it.name>_stack.push(new <it.name>_scope());}; separator="\n">
<if(ruleDescriptor.hasMultipleReturnValues)>
<returnType()> retval = new <returnType()>();
retval.start = (<labelType>)input.LT(1);<\n>
<else>
<if(ruleDescriptor.hasSingleReturnValue)>
<returnType()> <ruleDescriptor.singleValueReturnName>;
<endif>
<endif>
<if(memoize)>
int <ruleDescriptor.name>_StartIndex = input.index();
<endif>
>>

ruleLabelDefs() ::= <<
<[ruleDescriptor.tokenLabels,ruleDescriptor.tokenListLabels]
    :{<labelType> <it.label.text>=null;}; separator="\n"
>
<[ruleDescriptor.tokenListLabels,ruleDescriptor.ruleListLabels]
    :{List list_<it.label.text>=null;}; separator="\n"
>
<[ruleDescriptor.ruleLabels,ruleDescriptor.ruleListLabels]
    :ruleLabelDef(label=it); separator="\n"
>
<[ruleDescriptor.allRuleRefsInAltsWithRewrites,ruleDescriptor.allTokenRefsInAltsWithRewrites]
    :{List list_<it>=new ArrayList();}; separator="\n"
>
>>

ruleReturnValue() ::= <<
<if(ruleDescriptor.hasReturnValue)>
<if(ruleDescriptor.hasSingleReturnValue)>
<ruleDescriptor.singleValueReturnName>
<else>
retval
<endif>
<endif>
>>

ruleCleanUp() ::= <<
<ruleDescriptor.useScopes:{<it>_stack.pop();}; separator="\n">
<ruleDescriptor.ruleScope:{<it.name>_stack.pop();}; separator="\n">
<if(ruleDescriptor.hasMultipleReturnValues)>
retval.stop = (<labelType>)input.LT(-1);
<endif>
<if(memoize)>
<if(backtracking)>
if ( backtracking>0 ) { memoize(input, <ruleDescriptor.index>, <ruleDescriptor.name>_StartIndex); }
<endif>
<endif>
>>

/** How to generate a rule in the lexer; naked blocks are used for
 *  fragment rules.
 */
lexerRule(ruleName,nakedBlock,ruleDescriptor,block) ::= <<
public void m<ruleName>(<ruleDescriptor.parameterScope:parameterScope(scope=it)>) throws RecognitionException {
<ruleDescriptor.actions.init>
<if(nakedBlock)>
    <block><\n>
<else>
    int type = <ruleName>;
    int start = getCharIndex();
    int line = getLine();
    int charPosition = getCharPositionInLine();
    int channel = Token.DEFAULT_CHANNEL;
    <block>
    if ( token==null ) {emit(type,line,charPosition,channel,start,getCharIndex()-1);}<\n>
<endif>
}
>>

/** How to generate code for the implicitly-defined lexer grammar rule
 *  that chooses between lexer rules.
 */
tokensRule(ruleName,nakedBlock,args,block,ruleDescriptor) ::= <<
public void mTokens() throws RecognitionException {
    <block><\n>
}
>>

// S U B R U L E S

/** A (...) subrule with multiple alternatives */
block(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<
// <fileName>:<description>
int alt<decisionNumber>=<maxAlt>;
<decls>
<@predecision()>
<decision>
<@postdecision()>
<@prebranch()>
switch (alt<decisionNumber>) {
    <alts:altSwitchCase()>
}
<@postbranch()>
>>

/** A rule block with multiple alternatives */
ruleBlock(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<
// <fileName>:<description>
int alt<decisionNumber>=<maxAlt>;
<decls>
<@predecision()>
<decision>
<@postdecision()>
switch (alt<decisionNumber>) {
    <alts:altSwitchCase()>
}
>>

ruleBlockSingleAlt(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,description) ::= <<
// <fileName>:<description>
<decls>
<@prealt()>
<alts>
<@postalt()>
>>

/** A special case of a (...) subrule with a single alternative */
blockSingleAlt(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,description) ::= <<
// <fileName>:<description>
<decls>
<@prealt()>
<alts>
<@postalt()>
>>

/** A (..)+ block with 0 or more alternatives */
positiveClosureBlock(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<
// <fileName>:<description>
int cnt<decisionNumber>=0;
<decls>
<@preloop()>
loop<decisionNumber>:
do {
    int alt<decisionNumber>=<maxAlt>;
    <@predecision()>
    <decision>
    <@postdecision()>
    switch (alt<decisionNumber>) {
	<alts:altSwitchCase()>
	default :
	    if ( cnt<decisionNumber> >= 1 ) break loop<decisionNumber>;
	    <ruleBacktrackFailure()>
            EarlyExitException eee =
                new EarlyExitException(<decisionNumber>, input);
            <@earlyExitException()>
            throw eee;
    }
    cnt<decisionNumber>++;
} while (true);
<@postloop()>
>>

positiveClosureBlockSingleAlt ::= positiveClosureBlock

/** A (..)* block with 0 or more alternatives */
closureBlock(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<
// <fileName>:<description>
<decls>
<@preloop()>
loop<decisionNumber>:
do {
    int alt<decisionNumber>=<maxAlt>;
    <@predecision()>
    <decision>
    <@postdecision()>
    switch (alt<decisionNumber>) {
	<alts:altSwitchCase()>
	default :
	    break loop<decisionNumber>;
    }
} while (true);
<@postloop()>
>>

closureBlockSingleAlt ::= closureBlock

/** Optional blocks (x)? are translated to (x|) by before code generation
 *  so we can just use the normal block template
 */
optionalBlock ::= block

optionalBlockSingleAlt ::= block

/** A case in a switch that jumps to an alternative given the alternative
 *  number.  A DFA predicts the alternative and then a simple switch
 *  does the jump to the code that actually matches that alternative.
 */
altSwitchCase() ::= <<
case <i> :
    <@prealt()>
    <it>
    break;<\n>
>>

/** An alternative is just a list of elements; at outermost level */
alt(elements,altNum,description,autoAST,outerAlt) ::= <<
// <fileName>:<description>
{
<@declarations()>
<elements:element()>
<@cleanup()>
}
>>

// E L E M E N T S

/** Dump the elements one per line */
element() ::= <<
<@prematch()>
<it.el><\n>
>>

/** match a token optionally with a label in front */
tokenRef(token,label,elementIndex) ::= <<
<if(label)>
<label>=(<labelType>)input.LT(1);<\n>
<endif>
match(input,<token>,FOLLOW_<token>_in_<ruleName><elementIndex>); <checkRuleBacktrackFailure()>
>>

/** ids+=ID */
tokenRefAndListLabel(token,label,elementIndex) ::= <<
<tokenRef(...)>
<listLabel(...)>
>>

listLabel(label) ::= <<
if (list_<label>==null) list_<label>=new ArrayList();
list_<label>.add(<label>);<\n>
>>

/** match a character */
charRef(char,label) ::= <<
<if(label)>
int <label> = input.LA(1);<\n>
<endif>
match(<char>); <checkRuleBacktrackFailure()>
>>

/** match a character range */
charRangeRef(a,b) ::= "matchRange(<a>,<b>); <checkRuleBacktrackFailure()>"

/** For now, sets are interval tests and must be tested inline */
matchSet(s,label,elementIndex,postmatchCode="") ::= <<
<if(label)>
<label>=(<labelType>)input.LT(1);<\n>
<endif>
if ( <s> ) {
    <postmatchCode>
    input.consume();
<if(!LEXER)>
    errorRecovery=false;
<endif>
    <if(backtracking)>failed=false;<endif>
}
else {
    <ruleBacktrackFailure()>
    MismatchedSetException mse =
        new MismatchedSetException(null,input);
    <@mismatchedSetException()>
<if(LEXER)>
    recover(mse);
<else>
    recoverFromMismatchedSet(input,mse,FOLLOW_set_in_<ruleName><elementIndex>);
<endif>
    throw mse;
}<\n>
>>

matchSetAndListLabel(s,label,elementIndex,postmatchCode) ::= <<
<matchSet(...)>
<listLabel(...)>
>>

/** Match a string literal */
lexerStringRef(string,label) ::= <<
<if(label)>
int <label>Start = getCharIndex();
match(<string>); <checkRuleBacktrackFailure()>
Token <label> = new CommonToken(input, Token.INVALID_TOKEN_TYPE, Token.DEFAULT_CHANNEL, <label>Start, getCharIndex()-1);
<else>
match(<string>); <checkRuleBacktrackFailure()><\n>
<endif>
>>

wildcard(label,elementIndex) ::= <<
<if(label)>
<label>=(<labelType>)input.LT(1);<\n>
<endif>
matchAny(input); <checkRuleBacktrackFailure()>
>>

wildcardAndListLabel(label,elementIndex) ::= <<
<wildcard(...)>
<listLabel(...)>
>>

/** Match . wildcard in lexer */
wildcardChar(label, elementIndex) ::= <<
<if(label)>
int <label> = input.LA(1);<\n>
<endif>
matchAny(); <checkRuleBacktrackFailure()>
>>

wildcardCharListLabel(label, elementIndex) ::= <<
<wildcardChar(...)>
<listLabel(...)>
>>

/** Match a rule reference by invoking it possibly with arguments
 *  and a return value or values.
 */
ruleRef(rule,label,elementIndex,args) ::= <<
following.push(FOLLOW_<rule>_in_<ruleName><elementIndex>);
<if(label)>
<label>=<rule>(<args>);<\n>
<else>
<rule>(<args>);<\n>
<endif>
following.pop();
<checkRuleBacktrackFailure()>
>>

/** ids+=ID */
ruleRefAndListLabel(rule,label,elementIndex,args) ::= <<
<ruleRef(...)>
<listLabel(...)>
>>

/** A lexer rule reference */
lexerRuleRef(rule,label,args) ::= <<
<if(label)>
int <label>Start = getCharIndex();
m<rule>(<args>); <checkRuleBacktrackFailure()>
Token <label> = new CommonToken(input, Token.INVALID_TOKEN_TYPE, Token.DEFAULT_CHANNEL, <label>Start, getCharIndex()-1);
<else>
m<rule>(<args>); <checkRuleBacktrackFailure()>
<endif>
>>

/** EOF in the lexer */
lexerMatchEOF(label) ::= <<
<if(label)>
int <label>Start = getCharIndex();
match(EOF); <checkRuleBacktrackFailure()>
Token <label> = new CommonToken(input, EOF, Token.DEFAULT_CHANNEL, <label>Start, getCharIndex()-1);
<else>
match(EOF); <checkRuleBacktrackFailure()>
<endif>
>>

/** match ^(root children) in tree parser */
tree(root, children) ::= <<
<root:element()>
match(input, Token.DOWN, null); <checkRuleBacktrackFailure()>
<children:element()>
match(input, Token.UP, null); <checkRuleBacktrackFailure()>
>>

/** Every predicate is used as a validating predicate (even when it is
 *  also hoisted into a prediction expression).
 */
validateSemanticPredicate(pred,description) ::= <<
if ( !(<evalPredicate(...)>) ) {
    <ruleBacktrackFailure()>
    throw new FailedPredicateException(input, "<ruleName>", "<description>");
}
>>

// F i x e d  D F A  (if-then-else)

dfaState(k,edges,eotPredictsAlt,description,stateNumber) ::= <<
int LA<decisionNumber>_<stateNumber> = input.LA(<k>);
<edges; separator="\nelse ">
else {
<if(eotPredictsAlt)>
    alt<decisionNumber>=<eotPredictsAlt>;
<else>
    <ruleBacktrackFailure()>
    NoViableAltException nvae =
        new NoViableAltException("<description>", <decisionNumber>, <stateNumber>, input);<\n>
    <@noViableAltException()>
    throw nvae;<\n>
<endif>
}
>>

/** Same as a normal DFA state except that we don't examine lookahead
 *  for the bypass alternative.  It delays error detection but this
 *  is faster, smaller, and more what people expect.  For (X)? people
 *  expect "if ( LA(1)==X ) match(X);" and that's it.
 */
dfaOptionalBlockState(k,edges,eotPredictsAlt,description,stateNumber) ::= <<
int LA<decisionNumber>_<stateNumber> = input.LA(<k>);
<edges; separator="\nelse ">
>>

/** A DFA state that is actually the loopback decision of a closure
 *  loop.  If end-of-token (EOT) predicts any of the targets then it
 *  should act like a default clause (i.e., no error can be generated).
 *  This is used only in the lexer so that for ('a')* on the end of a rule
 *  anything other than 'a' predicts exiting.
 */
dfaLoopbackState(k,edges,eotPredictsAlt,description,stateNumber) ::= <<
int LA<decisionNumber>_<stateNumber> = input.LA(<k>);
<edges; separator="\nelse "><\n>
<if(eotPredictsAlt)>
else {
    alt<decisionNumber>=<eotPredictsAlt>;
}<\n>
<endif>
>>

/** An accept state indicates a unique alternative has been predicted */
dfaAcceptState(alt) ::= "alt<decisionNumber>=<alt>;"

/** A simple edge with an expression.  If the expression is satisfied,
 *  enter to the target state.  To handle gated productions, we may
 *  have to evaluate some predicates for this edge.
 */
dfaEdge(labelExpr, targetState, predicates) ::= <<
if ( <labelExpr> <if(predicates)>&& <predicates><endif>) {
    <targetState>
}
>>

// F i x e d  D F A  (switch case)

/** A DFA state where a SWITCH may be generated.  The code generator
 *  decides if this is possible: CodeGenerator.canGenerateSwitch().
 */
dfaStateSwitch(k,edges,eotPredictsAlt,description,stateNumber) ::= <<
switch ( input.LA(<k>) ) {
<edges; separator="\n">
default:
<if(eotPredictsAlt)>
    alt<decisionNumber>=<eotPredictsAlt>;
<else>
    <ruleBacktrackFailure()>
    NoViableAltException nvae =
        new NoViableAltException("<description>", <decisionNumber>, <stateNumber>, input);<\n>
    <@noViableAltException()>
    throw nvae;<\n>
<endif>
}<\n>
>>

dfaOptionalBlockStateSwitch(k,edges,eotPredictsAlt,description,stateNumber) ::= <<
switch ( input.LA(<k>) ) {
    <edges; separator="\n">
}<\n>
>>

dfaLoopbackStateSwitch(k, edges,eotPredictsAlt,description,stateNumber) ::= <<
switch ( input.LA(<k>) ) {
<edges; separator="\n"><\n>
<if(eotPredictsAlt)>
default:
    alt<decisionNumber>=<eotPredictsAlt>;
    break;<\n>
<endif>
}<\n>
>>

dfaEdgeSwitch(labels, targetState) ::= <<
<labels:{case <it>:}; separator="\n">
    <targetState>
    break;
>>

// C y c l i c  D F A

/** The code to initiate execution of a cyclic DFA; this is used
 *  in the rule to predict an alt just like the fixed DFA case.
 *  The <name> attribute is inherited via the parser, lexer, ...
 */
dfaDecision(decisionNumber,description) ::= <<
alt<decisionNumber> = dfa<decisionNumber>.predict(input);
>>

/** The overall cyclic DFA chunk; contains all the DFA states */
cyclicDFA(className,ruleName,ruleDescriptor,decisionNumber,states,description) ::= <<
class DFA<decisionNumber> extends DFA {
    public int predict(IntStream input) throws RecognitionException {
        return predict(input, s0);
    }
    <states>
}
>>

/** A state in a cyclic DFA */
cyclicDFAState(stateNumber,edges,needErrorClause) ::= <<
DFA.State s<stateNumber> = new DFA.State() {
    public DFA.State transition(IntStream input) throws RecognitionException {
        int LA<decisionNumber>_<stateNumber> = input.LA(1);
        <edges>
        <if(needErrorClause)>
        <if(backtracking)>
        if (backtracking>0) {failed=true; return null;}
        <endif>
        NoViableAltException nvae =
	    new NoViableAltException("<description>", <decisionNumber>, <stateNumber>, input);<\n>
        <@noViableAltException()>
        throw nvae;
        <endif>
    }
};<\n>
>>

/** An accept state for a cyclic DFA */
cyclicDFAAcceptState(stateNumber,predictAlt) ::= <<
DFA.State s<stateNumber> = new DFA.State() {{alt=<predictAlt>;}};<\n>
>>

/** Just like a fixed DFA edge, test the lookahead and indicate what
 *  state to jump to next if successful.
 */
cyclicDFAEdge(labelExpr, targetStateNumber, edgeNumber, predicates) ::= <<
if ( <labelExpr> <if(predicates)>&& <predicates><endif>) {return s<targetStateNumber>;}<\n>
>>

/** An edge pointing at end-of-token; essentially matches any char;
 *  always jump to the target.
 */
eotDFAEdge(targetStateNumber,edgeNumber, predicates) ::= <<
return s<targetStateNumber>;<\n>
>>

// C y c l i c  S W I T C H

/* A repetition of the cyclic DFA states, but using switches instead
 * of if-then-else sequences.
 */

cyclicDFAStateSwitch(stateNumber,labels,edges,
                     needErrorClause,EOTTargetStateNumber) ::= <<
DFA.State s<stateNumber> = new DFA.State() {
    public DFA.State transition(IntStream input) throws RecognitionException {
        switch ( input.LA(1) ) {
        <edges; separator="\n">
        default:
<if(needErrorClause)>
            <if(backtracking)>
            if (backtracking>0) {failed=true; return null;}
            <endif>
            NoViableAltException nvae =
                new NoViableAltException("<description>", <decisionNumber>, <stateNumber>, input);<\n>
            throw nvae;
<else>
            return s<EOTTargetStateNumber>;<\n>	
<endif>
        }
    }
};<\n>
>>

cyclicDFAEdgeSwitch(labels, targetStateNumber, edgeNumber) ::= <<
<labels:{case <it>:}; separator="\n">
    return s<targetStateNumber>;<\n>
>>

// D F A  E X P R E S S I O N S

andPredicates(left,right) ::= "(<left>&&<right>)"

orPredicates(left,right) ::= "(<left>||<right>)"

notPredicate(pred) ::= "!(<evalPredicate(...)>)"

evalPredicate(pred,description) ::= "<pred>"

evalSynPredicate(pred,description) ::= 
  "synpred(input, <pred>)"

lookaheadTest(atom,k,atomAsInt) ::= "LA<decisionNumber>_<stateNumber>==<atom>"

/** Sometimes a lookahead test cannot assume that LA(k) is in a temp variable
 *  somewhere.  Must ask for the lookahead directly.
 */
isolatedLookaheadTest(atom,k,atomAsInt) ::= "input.LA(<k>)==<atom>"

lookaheadRangeTest(lower,upper,k,rangeNumber,lowerAsInt,upperAsInt) ::= <<
(LA<decisionNumber>_<stateNumber>\>=<lower> && LA<decisionNumber>_<stateNumber>\<=<upper>)
>>

isolatedLookaheadRangeTest(lower,upper,k,rangeNumber,lowerAsInt,upperAsInt) ::= "(input.LA(<k>)\>=<lower> && input.LA(<k>)\<=<upper>)"

setTest(ranges) ::= "<ranges; separator=\"||\">"

// A T T R I B U T E S

makeScopeSet() ::= <<
/** Definition of the <scope.name> scope variable tracking
 *  structure. An instance of this structure is created by calling
 *  <name>Parser_ctx-><name>_<scope.name>Stack_push().
 */
typedef struct  <name>_<scope.name>_SCOPE_STRUCT
{
    /** ANTLR3 C runtime scope controlling structure included
     *  in all scope stacked structures.
     */
    ANTLR3_SCOPE    scopeTracker;

    /* =============================================================================
     * Programmer defined variables...
     */
    <scope.attributes:{<it.decl>;}; separator="\n">

    /* End of programmer defined variables
     * =============================================================================
     */
} 
    * pANTLR3_<name>_<scope.name>_SCOPE;

>>

globalAttributeScopeDecl(scope) ::= 
<<
<if(scope.attributes)>
<makeScopeSet(...)>
<endif>
>>

ruleAttributeScopeDecl(scope) ::= 
<<
<if(scope.attributes)>
<makeScopeSet(...)>
<endif>
>>

globalAttributeScopeFuncDecl(scope) ::= 
<<
<if(scope.attributes)>
/* -----------------------------------------------------------------------------
 * Function declarations for creating and destroying a <name>_<scope.name> scope set 
 */
static  pANTLR3_<name>_<scope.name>_SCOPE
        <name>_<scope.name>Stack_push();
static  pANTLR3_<name>_<scope.name>_SCOPE
        <name>_<scope.name>Stack_pop();
/* ----------------------------------------------------------------------------- */

<endif>
>>

ruleAttributeScopeFuncDecl(scope) ::= 
<<
<if(scope.attributes)>
/* -----------------------------------------------------------------------------
 * Function declarations for creating and destroying a <name>_<scope.name> scope set 
 */
static  pANTLR3_<name>_<scope.name>_SCOPE
        <name>_<scope.name>Stack_push(<name>Ctx ctx);
static  void
        <name>_<scope.name>Stack_pop(<name>Ctx ctx);
/* ----------------------------------------------------------------------------- */

<endif>
>>

globalAttributeScopeDef(scope) ::= 
<<
<if(scope.attributes)>
/** Pointer to the top of the <scope.name> stack for use by <name>_<scope.name>Stack_push()
 *  and <name>_<scope.name>Stack_pop()
 */
static  pANTLR3_<scope.name>_SCOPE <name>_<scope.name>_stack;
<endif>
>>

ruleAttributeScopeDef(scope) ::=
<<
<if(scope.attributes)>
/** Pointer to the top of the <scope.name> stack for use by <name>_<scope.name>Stack_push()
 *  and <name>_<scope.name>Stack_pop()
 */
pANTLR3_<scope.name>_SCOPE <name>_<scope.name>_stack;
<endif>
>>

globalAttributeScopeFuncs(scope) ::= 
<<
<if(scope.attributes)>
<attributeFuncs(scope)>
<endif>
>>

ruleAttributeScopeFuncs(scope) ::=
<<
<if(scope.attributes)>
<attributeFuncs(scope)>
<endif>
>>

globalAttributeScope(scope) ::= 
<<
<if(scope.attributes)>
<name>_<scope.name>_stack = <name>_<scope.name>Stack_push();
<endif>
>>

ruleAttributeScope(scope) ::= 
<<
<if(scope.attributes)>
<name>_<scope.name>_stack = <name>_<scope.name>Stack_push();
<endif>
>>

attributeFuncs(scope) ::=
<<
<if(scope.attributes)>
/** \brief Allocate initial memory for a <name>_<scope.name> scope variable stack entry and
 *         add it to the top of the stack.
 */ 
pANTLR3_<name>_<scope.name>_SCOPE <name>_<scope.name>Stack_push(<name>Ctx ctx)
{
    /* Pointer used to create a new set of attributes
     */
    pANTLR3_<name>_<scope.name>_SCOPE      newAttributes;

    /* Allocate the memory for a new structure
     */
    newAttributes = (pANTLR3_<name>_<scope.name>_SCOPE)ANTRL3_MALLOC(sizeof(pANTLR3_<name>_<scope.name>_SCOPE));

    if  (newAttributes != NULL)
    {
        /* If the current entry on the top of stack is not NULL then we assign
         * it's previous pointer to the new entry
         */
        if  (ctx-><scope.name>Stack != NULL)
        {
            ctx-><name>_<scope.name>Stack->previous = newAttributes;
        }

        /* Assign the current stack top value to the next pointer
         * in the newly defined structure.
         */
        newAttributes->scopeTracker.next            = parserCtx-><name>_<scope.name>Stack;

        /* Make the top entry in the stack our newly defined entry
         */
        ctx-><scope.name>Stack                = newAttributes;
    }

    /* Return value is the pointer to the new entry, which may be used locally
     * without de-referencing via the context.
     */
    return  newAttributes;
}

/** \brief De-allocate a <name>_<scope.name> scope variable stack entry and
 *         remove it from the top of the stack.
 */ 
void    <name>_<scope.name>Stack_pop(<name>Ctx ctx)
{
    /* Pointer used to delete the top set of attributes
     */
    pANTLR3_<name>_<scope.name>_SCOPE      newAttributes;

    
}
<endif>
>>

returnType() ::= <<
<if(ruleDescriptor.hasMultipleReturnValues)>
p<ruleDescriptor.name>_return
<else>
<if(ruleDescriptor.hasSingleReturnValue)>
<ruleDescriptor.singleValueReturnType>
<else>
void
<endif>
<endif>
>>

/** Generate the Java type associated with a single or multiple return
 *  values.
 */
ruleLabelType(referencedRule) ::= <<
<if(referencedRule.hasMultipleReturnValues)>
<referencedRule.name>_return
<else>
<if(referencedRule.hasSingleReturnValue)>
<referencedRule.singleValueReturnType>
<else>
void
<endif>
<endif>
>>

/** Using a type to init value map, try to init a type; if not in table
 *  must be an object, default value is "null".
 */
initValue(typeName) ::= <<
<javaTypeInitMap.(typeName)>
>>

/** Define a rule label including default value */
ruleLabelDef(label) ::= <<
<ruleLabelType(referencedRule=label.referencedRule)> <label.label.text> = <initValue(typeName=ruleLabelType(referencedRule=label.referencedRule))>;<\n>
>>

/** Define a return struct for a rule if the code needs to access its
 *  start/stop tokens, tree stuff, attributes, ...  Leave a hole for
 *  subgroups to stick in members.
 */
returnScope(scope) ::= <<
<if(ruleDescriptor.hasMultipleReturnValues)>
typedef struct <returnType()>_STRUCT 
{
    /** Generic return elements for ANTLR3 rules
     */
<if(TREE_PARSER)>
    ANTLR3_TREE_RULE_RETURN_SCOPE   antlr3ReturnScope;
<endif>
<if(PARSER)>
    ANTLR3_RULE_RETURN_SCOPE        antlr3ReturnScope;
<endif>

    <scope.attributes:{<it.decl>;}; separator="\n">
    <@ruleReturnMembers()>   
}
    * <returnType()>;
<endif>
>>

parameterScope(scope) ::= <<
<scope.attributes:{<it.decl>}; separator=", ">
>>

/** Used in codegen.g to translate $x.y references.
 *  I could have left actions as StringTemplates to be inserted in
 *  the output (so they could use attributes inherited from surrounding
 *  templates), but really wanted to pass in AttributeScope and Attribute
 *  objects so this translation could query them.  So, translation of
 *  $x.y to executable code occurs before recognizerST.toString() occurs.
 *  I.e., actions are just text strings during final code generation.
 */
globalAttributeRef(scope,attr) ::= <<
((<scope>)<scope>_stack.peek()).<attr.name>
>>

parameterAttributeRef(attr) ::= "<attr.name>"

ruleScopeAttributeRef(scope,attr) ::=
    "((<scope>_scope)<scope>_stack.peek()).<attr.name>"

/** $x is either global scope or x is rule with dynamic scope; refers
 *  to stack itself not top of stack.  This is useful for predicates
 *  like {$function.size()>0 && $function::name.equals("foo")}?
 */
isolatedDynamicScopeRef(scope) ::= "<scope>_stack"

/** reference an attribute of rule; might only have single return value */
ruleLabelRef(referencedRule,scope,attr) ::= <<
<if(referencedRule.hasMultipleReturnValues)>
<scope>.<attr.name>
<else>
<scope>
<endif>
>>

returnAttributeRef(ruleDescriptor,attr) ::= <<
<if(ruleDescriptor.hasMultipleReturnValues)>
retval.<attr.name>
<else>
<attr.name>
<endif>
>>

/** How to translate $tokenLabel */
tokenLabelRef(label) ::= "<label>"

/** ids+=ID {$ids} or e+=expr {$e} */
listLabelRef(label) ::= "list_<label>"


// not sure the next are the right approach; and they are evaluated early;
// they cannot see TREE_PARSER or PARSER attributes for example. :(

tokenLabelPropertyRef_text(scope,attr) ::= "<scope>.getText()"
tokenLabelPropertyRef_type(scope,attr) ::= "<scope>.getType()"
tokenLabelPropertyRef_line(scope,attr) ::= "<scope>.getLine()"
tokenLabelPropertyRef_pos(scope,attr) ::= "<scope>.getCharPositionInLine()"
tokenLabelPropertyRef_channel(scope,attr) ::= "<scope>.getChannel()"
tokenLabelPropertyRef_index(scope,attr) ::= "<scope>.getTokenIndex()"
tokenLabelPropertyRef_tree(scope,attr) ::= "<scope>_tree"

ruleLabelPropertyRef_start(scope,attr) ::= "<scope>.start"
ruleLabelPropertyRef_stop(scope,attr) ::= "<scope>.stop"
ruleLabelPropertyRef_tree(scope,attr) ::= "<scope>.tree"
ruleLabelPropertyRef_text(scope,attr) ::= "input.toString(<scope>.start,<scope>.stop)"
ruleLabelPropertyRef_st(scope,attr) ::= "<scope>.st"

lexerRuleLabelPropertyRef_type(scope,attr) ::= "<scope>.getType()"
lexerRuleLabelPropertyRef_line(scope,attr) ::= "<scope>.getLine()"
lexerRuleLabelPropertyRef_pos(scope,attr) ::= "<scope>.getCharPositionInLine()"
lexerRuleLabelPropertyRef_channel(scope,attr) ::= "<scope>.getChannel()"
lexerRuleLabelPropertyRef_index(scope,attr) ::= "<scope>.getTokenIndex()"
lexerRuleLabelPropertyRef_text(scope,attr) ::= "<scope>.getText()"

// Somebody may ref $template or $tree or $stop within a rule:
rulePropertyRef_start(scope,attr) ::= "retval.start"
rulePropertyRef_stop(scope,attr) ::= "retval.stop"
rulePropertyRef_tree(scope,attr) ::= "retval.tree"
rulePropertyRef_text(scope,attr) ::= "input.toString(retval.start,input.LT(-1))"
rulePropertyRef_st(scope,attr) ::= "retval.st"


/** How to execute an action */
execAction(action) ::= <<
<if(backtracking)>
if ( backtracking==0 ) {
  <action>
}
<else>
<action>
<endif>
>>

// L E X E R  A C T I O N S

emit(type) ::= "emit(<type>);"

setType(type) ::= "setType(<type>);"

// M I S C (properties, etc...)

bitset(name, words64) ::= <<
public static final BitSet <name> = new BitSet(new long[]{<words64:{<it>L};separator=",">});<\n>
>>

codeFileExtension() ::= ".c"

true() ::= "true"
false() ::= "false"
